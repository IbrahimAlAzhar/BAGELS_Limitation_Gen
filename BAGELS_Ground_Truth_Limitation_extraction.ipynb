{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqVlczArGoFd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "generated_summary = []\n",
        "# abstracts = []\n",
        "\n",
        "for i in range(len(df1)): # len(df1)\n",
        "    #prompt = \"Objective: Generate summary for the following passage from a scientific paper. Consider the Abstract, Introduction, and other sections of a scientific paper. Each summary should be 200 to 300 words. \\n\\n\" + \"Abstract:\\n\" + df_cleaned['Abstract'][i] + \"\\n\" + \"Introduction:\\n\" + df_cleaned['Introduction'][i] + \"Others:\\n\" + df_cleaned['col_1'][i] + \"\\n\" +  df_cleaned['col_2'][i] + \"\\n\" + df_cleaned['col_3'][i] + \"\\n\" +  df_cleaned['col_4'][i] + \"\\n\" +  df_cleaned['col_5'][i] + \"\\n\" +  df_cleaned['col_6'][i] + \"\\n\" + df_cleaned['col_7'][i] + \"\\n\"\n",
        "    prompt = f\"\"\"\n",
        "    Here is a limitation. Extract sub limitation from this limitation. Each sub limitation\n",
        "    contains separate topics, limitation or point. \\n{df1['Limitation'][i]}\n",
        "    \"\"\"\n",
        "\n",
        "    summary_text = \"\"  # Initialize an empty string to collect the limitation text\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        stream=True,\n",
        "        temperature=0 # Adjust the temperature as needed, max_tokens=150\n",
        "    )\n",
        "\n",
        "    for chunk in stream:\n",
        "        summary_chunk = chunk.choices[0].delta.content or \"\"\n",
        "        # print(limitation_chunk, end=\"\")\n",
        "        summary_text += summary_chunk  # Append each chunk to the limitation_text\n",
        "\n",
        "    # print(\"\\n\")  # Print a newline for readability\n",
        "    summary_chunks = []\n",
        "    summary_chunks.append(summary_text)\n",
        "    generated_summary.append(summary_chunks)  # Append the collected limitation text to the list\n"
      ]
    }
  ]
}