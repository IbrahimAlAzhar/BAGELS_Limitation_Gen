{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "3 sections"
      ],
      "metadata": {
        "id": "zx0ojPZoMy54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-3VtNweMH8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "generated_summary = []\n",
        "# abstracts = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    #prompt = \"Objective: Generate summary for the following passage from a scientific paper. Consider the Abstract, Introduction, and other sections of a scientific paper. Each summary should be 200 to 300 words. \\n\\n\" + \"Abstract:\\n\" + df_cleaned['Abstract'][i] + \"\\n\" + \"Introduction:\\n\" + df_cleaned['Introduction'][i] + \"Others:\\n\" + df_cleaned['col_1'][i] + \"\\n\" +  df_cleaned['col_2'][i] + \"\\n\" + df_cleaned['col_3'][i] + \"\\n\" +  df_cleaned['col_4'][i] + \"\\n\" +  df_cleaned['col_5'][i] + \"\\n\" +  df_cleaned['col_6'][i] + \"\\n\" + df_cleaned['col_7'][i] + \"\\n\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful, respectful, and honest assistant for generating limitations or shortcomings of a research paper.\n",
        "    I am providing 'Abstract', 'Introduction', and 'Conclusion' of a scientific paper.\n",
        "    Generate limitations based on these texts. \\n{df['response_string'][i]}\n",
        "    \"\"\"\n",
        "\n",
        "    summary_text = \"\"  # Initialize an empty string to collect the limitation text\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        # model=\"gpt-3.5-turbo\",\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        stream=True,\n",
        "        temperature=0.1  # Adjust the temperature as needed, max_tokens=150\n",
        "    )\n",
        "\n",
        "    for chunk in stream:\n",
        "        summary_chunk = chunk.choices[0].delta.content or \"\"\n",
        "        # print(limitation_chunk, end=\"\")\n",
        "        summary_text += summary_chunk  # Append each chunk to the limitation_text\n",
        "\n",
        "    # print(\"\\n\")  # Print a newline for readability\n",
        "    summary_chunks = []\n",
        "    summary_chunks.append(summary_text)\n",
        "    generated_summary.append(summary_chunks)  # Append the collected limitation text to the list\n",
        "    time.sleep(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All sections"
      ],
      "metadata": {
        "id": "Q2IHeALAM0vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['response_string'] = df.apply(lambda row: f\"\"\"Abstract: {row['Abstract']}\n",
        "Introduction: {row['Introduction']}\n",
        "Related_Work: {row['Related_Work']}\n",
        "Methodology: {row['Methodology']}\n",
        "Dataset: {row['Dataset']}\n",
        "Conclusion: {row['Conclusion']}\n",
        "\"\"\", axis=1)"
      ],
      "metadata": {
        "id": "J2MSIzKkM2uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "generated_summary = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful, respectful, and honest assistant for generating limitations or shortcomings of a research paper.\n",
        "    I am providing 'Abstract', 'Introduction', 'Related_Work', 'Methodology', 'Dataset' and\n",
        "    'Conclusion' of a scientific paper.\n",
        "    Generate limitations based on these texts. \\n{df['response_string'][i]}\n",
        "    \"\"\"\n",
        "\n",
        "    summary_text = \"\"\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        stream=True,\n",
        "        temperature=0.1  # Adjust the temperature as needed, max_tokens=150\n",
        "    )\n",
        "\n",
        "    for chunk in stream:\n",
        "        summary_chunk = chunk.choices[0].delta.content or \"\"\n",
        "        # print(limitation_chunk, end=\"\")\n",
        "        summary_text += summary_chunk\n",
        "\n",
        "    summary_chunks = []\n",
        "    summary_chunks.append(summary_text)\n",
        "    generated_summary.append(summary_chunks)\n",
        "    time.sleep(7)"
      ],
      "metadata": {
        "id": "KYa0AtPZNQIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}